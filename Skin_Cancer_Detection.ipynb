{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olKKVRcgcTXB"
      },
      "outputs": [],
      "source": [
        "# Set up CUDA in OS\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "# Import libabries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import *\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms as T\n",
        "from torchvision import datasets, models, transforms\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import cv2 as cv\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check version of Pytorch\n",
        "print(torch. __version__)"
      ],
      "metadata": {
        "id": "TOLgHMbpKI7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "7M5GXV1FKMpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/home/rugved/Rugved/SkinCancerDetection/Skin cancer dataset/train\"\n",
        "test_dir = \"/home/rugved/Rugved/SkinCancerDetection/Skin cancer dataset/test/\"\n",
        "train_classa_dir = \"/home/rugved/Rugved/SkinCancerDetection/Skin cancer dataset/train/benign/\"\n",
        "train_classb_dir = \"/home/rugved/Rugved/SkinCancerDetection/Skin cancer dataset/train/malignant/\"\n",
        "test_classa_dir = \"/home/rugved/Rugved/SkinCancerDetection/Skin cancer dataset/test/benign/\"\n",
        "test_classb_dir = \"/home/rugved/Rugved/SkinCancerDetection/Skin cancer dataset/test/malignant/\""
      ],
      "metadata": {
        "id": "nQUOegU8KQ9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "white_torch = torchvision.io.read_image('/home/rugved/Rugved/SkinCancerDetection/Skin cancer dataset/test/benign/1.jpg')\n",
        "print(\"This is benign skin cancer\")\n",
        "T.ToPILImage()(white_torch)"
      ],
      "metadata": {
        "id": "Q7ie5yFHKlU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image for reference\n",
        "wh = torchvision.io.read_image('/home/rugved/Rugved/SkinCancerDetection/Skin cancer dataset/test/benign/44.jpg')\n",
        "print(\"This is malignant skin cancer\")\n",
        "T.ToPILImage()(wh)"
      ],
      "metadata": {
        "id": "dcTy6LGmKoCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),   #must same as here\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(), # data augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization\n",
        "])\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),   #must same as here\n",
        "     transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "VmFaGg9rKrB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(train_dir, transforms_train)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transforms_test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=12, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "kvZOxQi9KtCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train dataset size:', len(train_dataset))\n",
        "print('Test dataset size:', len(test_dataset))\n",
        "class_names = train_dataset.classes\n",
        "print('Class names:', class_names)"
      ],
      "metadata": {
        "id": "2LArjwCsKuyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model"
      ],
      "metadata": {
        "id": "BSGDsYzqKwXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = model.fc.in_features\n",
        "print('Number of features from pre-trained model', num_features)"
      ],
      "metadata": {
        "id": "5uOFmimuKzhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(num_features, 2)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "HvDVbtQnK09a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
      ],
      "metadata": {
        "id": "wzvGHxRCK3EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "train_loss=[]\n",
        "train_accuary=[]\n",
        "test_loss=[]\n",
        "test_accuary=[]\n",
        "\n",
        "num_epochs = 30   #(set no of epochs)\n",
        "start_time = time.time() #(for showing time)\n",
        "# Start loop\n",
        "for epoch in range(num_epochs): #(loop for every epoch)\n",
        "    print(\"Epoch {} running\".format(epoch)) #(printing message)\n",
        "    \"\"\" Training Phase \"\"\"\n",
        "    model.train()    #(training model)\n",
        "    running_loss = 0.   #(set loss 0)\n",
        "    running_corrects = 0\n",
        "    # load a batch data of images\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # forward inputs and get output\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # get loss value and update the network weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
        "    # Append result\n",
        "    train_loss.append(epoch_loss)\n",
        "    train_accuary.append(epoch_acc)\n",
        "    # Print progress\n",
        "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch+1, epoch_loss, epoch_acc, time.time() -start_time))\n",
        "    \"\"\" Testing Phase \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_loss = 0.\n",
        "        running_corrects = 0\n",
        "        for inputs, labels in test_dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            running_corrects += torch.sum(preds == labels.data).item()\n",
        "        epoch_loss = running_loss / len(test_dataset)\n",
        "        epoch_acc = running_corrects / len(test_dataset) * 100.\n",
        "        # Append result\n",
        "        test_loss.append(epoch_loss)\n",
        "        test_accuary.append(epoch_acc)\n",
        "        # Print progress\n",
        "        print('[Test #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch+1, epoch_loss, epoch_acc, time.time()- start_time))"
      ],
      "metadata": {
        "id": "H98Kg_94K4kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "R9HwEOzQLBV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(np.arange(1,num_epochs+1), train_accuary,'-o')\n",
        "plt.plot(np.arange(1,num_epochs+1), test_accuary,'-o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train','Test'])\n",
        "plt.title('Train vs Test Accuracy over time')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9LmueN54LDc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "num_epochs = 30   #(set no of epochs)\n",
        "start_time = time.time() #(for showing time)\n",
        "# Start loop\n",
        "for epoch in range(num_epochs): #(loop for every epoch)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs) # Feed Network\n",
        "            outputs = (torch.max(torch.exp(outputs), 1)[1]).data.cpu().numpy()\n",
        "            y_pred.extend(outputs) # Save Prediction\n",
        "            labels = labels.data.cpu().numpy()\n",
        "            y_true.extend(labels) # Save Truth"
      ],
      "metadata": {
        "id": "fDO4BFnWLFsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = test_dataset.classes\n",
        "# Build confusion matrix\n",
        "print(\"Accuracy on Training set: \",accuracy_score(y_true, y_pred))\n",
        "print('Confusion matrix: \\n', confusion_matrix(y_true, y_pred))\n",
        "print('Classification report: \\n', classification_report(y_true, y_pred))\n",
        "# Plot\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cf_matrix, index = [i for i in classes], columns = [i for i in classes])\n",
        "plt.figure(figsize = (7,7))\n",
        "plt.title(\"Confusion matrix for Skin Cancer classification \")\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "metadata": {
        "id": "A3_bVIZ3LIG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "mGtCLV_2N13J",
        "outputId": "0b3e167b-0e4d-4296-e76e-9602864ce8f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The domain policy has disabled Drive File Stream: https://support.google.com/a/answer/7496409",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    289\u001b[0m       \u001b[0;31m# Now kill bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m       \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGKILL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m    292\u001b[0m           \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain_disabled_drivefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m           \u001b[0;34m+\u001b[0m \u001b[0;34m': https://support.google.com/a/answer/7496409'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The domain policy has disabled Drive File Stream: https://support.google.com/a/answer/7496409"
          ]
        }
      ]
    }
  ]
}